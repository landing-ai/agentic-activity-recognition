````markdown
<!--
  README for Activityâ€‘/Entityâ€‘Recognition Streamlit Demo
  Maintainers: @yourâ€‘githubâ€‘handle
  Last updated: 2025â€‘06â€‘11
-->

# ğŸƒâ€â™‚ï¸  Activityâ€‘ / Entityâ€‘ RecognitionÂ Â·Â Streamlit Demo

A selfâ€‘contained Streamlit app that lets you:

1. **Upload or liveâ€‘stream video** (â‰¤â€¯30â€¯min per file or continuous RTSP/WebRTC chunks).  
2. Send **naturalâ€‘language prompts** to Landingâ€¯AIâ€™s `POST /tools/activity_recognition` endpoint.  
3. **Step through detected events**â€”timestamps, bounding boxes, descriptionsâ€”inside the browser.  
4. **Experiment with recall vs. precision** via the builtâ€‘in **Specificity** slider.  

> **Important**  
> This demo is for **prompt design and quick validation**.  
> For production youâ€™ll likely wrap the same HTTPS calls in a queue / async worker.

---

## 0. Table of Contents
1. [Architecture](#1-architecture)
2. [Prerequisites](#2-prerequisites)
3. [Installation (Two Options)](#3-installation)
4. [Configuration](#4-configuration)
5. [Running the App](#5-running-the-app)
6. [Using the App](#6-using-the-app)
7. [Extending the Demo](#7-extending-the-demo)
8. [Troubleshooting](#8-troubleshooting)
9. [FAQ](#9-faq)
10. [Security Notes](#10-security-notes)
11. [Contributing](#11-contributing)
12. [Roadmap](#12-roadmap)
13. [License](#13-license)
14. [Contact](#14-contact)

---

## 1. Architecture <a id="1-architecture"></a>

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        HTTPS POST            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit App  â”‚  â€”â€”â–º  /tools/activity_recognition  â€”â€”â–º  â”‚ Landingâ€¯AI API (SaaS) â”‚
â”‚  (PythonÂ 3.9+) â”‚        JSON response         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ temp files / RTSP chunks
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local Storage  â”‚  (deleted on exit)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

*All computerâ€‘vision heavy liftingâ€”decoding, frame sampling, multimodal reasoningâ€”
occurs on Landingâ€¯AIâ€™s side. You only send bytes + prompts and receive JSON.*

---

## 2. Prerequisites <a id="2-prerequisites"></a>

| Requirement               | Version                 | Why                                                |
| ------------------------- | ----------------------- | -------------------------------------------------- |
| **Python**                | Â 3.9Â â€“Â 3.12             | Tested on 3.11.                                    |
| **Streamlit**             | Â 1.34+                  | UI layer.                                          |
| **ffmpeg**                | *latest* **(optional)** | Enables webcam / RTSP ingestion.                   |
| **Landingâ€¯AI account**    | API key (`VA_KEY`)      | Auth header for all requests.                      |
| **macOS, Linux, or WSL2** | â€”                       | Windows native should work; not officially tested. |

---

## 3. Installation <a id="3-installation"></a>

### OptionÂ AÂ Â·Â VirtualÂ Environment (recommended)

```bash
git clone https://github.com/yourâ€‘org/activityâ€‘recâ€‘demo.git
cd activityâ€‘recâ€‘demo/streamlit

python -m venv .venv
source .venv/bin/activate

# Upgrade pip first
pip install --upgrade pip

# Install Python deps
pip install -r requirements.txt
```

### OptionÂ BÂ Â·Â DockerÂ Compose

```bash
git clone https://github.com/yourâ€‘org/activityâ€‘recâ€‘demo.git
cd activityâ€‘recâ€‘demo

# Build and run
docker compose up --build
```

*The Dockerfile uses python:3.11â€‘slim, installs streamlit + dependencies, and exposes portâ€¯8501.*

---

## 4. Configuration <a id="4-configuration"></a>

Set your Landingâ€¯AI key **once per shell**:

```bash
export VA_KEY="skâ€‘yourâ€‘keyâ€‘here"
```

> **Never** commit API keys to Git. Use a secretsâ€‘manager (AWS Secrets Manager, HashiCorpâ€¯Vault, 1PasswordÂ CLI) in production.

---

## 5. Running the App <a id="5-running-the-app"></a>

```bash
# If using virtualenv
streamlit run app.py
```

Navigate to **[http://localhost:8501](http://localhost:8501)**. The app autorefreshes on code edits.

---

## 6. Using the App <a id="6-using-the-app"></a>

| UI Element             | Detailed Behavior                                                                                                       |
| ---------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **UploadÂ Video**       | Accepts MP4, MOV, AVI. Max length 30â€¯min. Files saved to OS temp dir and deleted when the session ends.                 |
| **PromptÂ Input**       | Plain English. Separate multiple activities/entities with `;`. Example: `ball crosses net; ace serve; double fault`.    |
| **ProcessÂ Audio**      | CheckedÂ = fuse sound cues. Helpful to separate visually similar scenes.                                                 |
| **SpecificityÂ Slider** | `low` (high recall) â†’ `max` (high precision). Maps 1â€‘toâ€‘1 with the APIâ€™s `specificity` fieldâ€”no clientâ€‘side heuristics. |
| **RunÂ Analysis**       | Calls `process_video()` â†’ uploads file â†’ displays spinner until JSON arrives.                                           |
| **ResultsÂ Table**      | Timestamp (`start_time`, `end_time`), `location`, `description`, `label` fields displayed via `st.dataframe()`.         |
| **Prev / Next**        | Updates session state and seeks the embedded video to the exact boundary of the selected event.                         |
| **RawÂ JSON**           | Always visible for copy/paste or downstream scripting.                                                                  |

---

## 7. Extending the Demo <a id="7-extending-the-demo"></a>

### 7.1 Realâ€‘Time Scoreboard Overlay (Tennis Example)

> **File:** `examples/scoreboard_overlay.py` (included in repo)
> **Why:** Proves lowâ€‘latency streaming without embedding storage.

1. **Run a local RTSP camera** or use `ffmpeg` to play an existing clip as RTSP:

   ```bash
   ffmpeg -re -i tennis.mp4 -c copy -f rtsp rtsp://localhost:8554/live
   ```
2. In **Streamlit**, choose **Live Stream** and paste `rtsp://localhost:8554/live`.
3. Prompt:

   ```
   ball crosses net; ace serve; double fault
   ```
4. The helper script listens to `st.session_state.results` websocket, counts `label`
   occurrences, and draws an SVG overlay on top of the video feed.

### 7.2Â BatchÂ Processing

For hourâ€‘long CCTV footage:

```python
from glob import glob
from utils import upload_in_chunks

for vid in glob("night_shift/*.mp4"):
    for chunk_path in upload_in_chunks(vid, chunk_len=60):
        events = process_video(chunk_path, prompt, True, "medium")
        save(events)          # your persistence layer
```

---

## 8. Troubleshooting <a id="8-troubleshooting"></a>

| Symptom                     | Likely Cause                             | Fix                                                                |
| --------------------------- | ---------------------------------------- | ------------------------------------------------------------------ |
| **`429 Too Many Requests`** | Hitting concurrency limit                | Exponential backâ€‘off; respect `Retryâ€‘After`.                       |
| **File upload hangs**       | File >â€¯5â€¯GB at 1080p                     | Trim file or lower resolution; API hardâ€‘limit at 30â€¯min.           |
| **Blank event list**        | Too strict `specificity` OR vague prompt | Lower specificity or refine prompt (e.g., â€œorange vest forkliftâ€). |
| **`401 Unauthorized`**      | Missing / wrong key                      | `echo $VA_KEY` and compare with Landingâ€¯AI console.                |
| **Webcam not visible**      | Browser permission                       | Grant camera access; ensure HTTPS if deploying remotely.           |

---

## 9. FAQ <a id="9-faq"></a>

1. **Does this store video on Landingâ€¯AIâ€™s servers?**
   Clips are retained only long enough for inference; no longâ€‘term storage.

2. **Is there a size limit?**
   30â€¯min per call; \~5â€¯GB at 1080p. Chunk longer videos clientâ€‘side.

3. **Can I run this offline?**
   No. The model is proprietary and hosted; local inference is not supported.

4. **What codecs work?**
   Anything ffmpeg can convert to H.264 inside MP4/MOV/AVI.

---

## 10. Security Notes <a id="10-security-notes"></a>

* Rotate `VA_KEY` at least every 90â€¯days.
* Prefer a shortâ€‘lived token wrapper when deploying in CI/CD.
* Use HTTPS everywhere; avoid proxying through mixedâ€‘content paths.

---

## 11. Contributing <a id="11-contributing"></a>

```text
Fork âœ Feature Branch âœ PR âœ Code Review âœ Merge
```

* Run `pre-commit install` to autoâ€‘format with black + isort.
* Add unit tests in `tests/` for new utility functions.

---

## 12. Roadmap <a id="12-roadmap"></a>

* [ ] Dragâ€‘&â€‘drop ROI to limit detection to zones.
* [ ] Builtâ€‘in WebRTC server for truly live ingestion.
* [ ] Darkâ€‘mode and mobileâ€‘responsive UI.

---

## 13. License <a id="13-license"></a>

```text
MIT License â€“ see LICENSE file.  
Landingâ€¯AI logo and name are trademarks; used with permission.
```

---

## 14. Contact <a id="14-contact"></a>

| Channel       | Handle / URL                                                                                                 |
| ------------- | ------------------------------------------------------------------------------------------------------------ |
| GitHub Issues | [https://github.com/yourâ€‘org/activityâ€‘recâ€‘demo/issues](https://github.com/yourâ€‘org/activityâ€‘recâ€‘demo/issues) |
| Support Email         | [support@landing.ai](mailto:support@landing.ai)                                                      |

---
